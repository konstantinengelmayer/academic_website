[{"content":" Marked Assignment: Recreation vs. Settlement First we simply read the .RDS file provided.\ndata \u0026lt;- readRDS(file = \u0026quot;../../data/lu_clean.RDS\u0026quot;)\rLinear Model Here we calculate the linear model. After calculating the model, we create the equation to be displayed within the plot. Lastly we create the plot with the ggplot package.\nlibrary(ggplot2)\rmodel \u0026lt;- lm(Settlement ~ Recreation, data)\r# Calculate model coefficients for the label\rintercept \u0026lt;- round(coef(model)[1], 3)\rslope \u0026lt;- round(coef(model)[2], 3)\requation_label \u0026lt;- paste0(\u0026quot;y = \u0026quot;, intercept, \u0026quot; + \u0026quot;, slope, \u0026quot;x\u0026quot;)\rr_squared \u0026lt;- summary(model)$r.squared\rlabel \u0026lt;- paste(equation_label, \u0026quot;\\nR-squared = \u0026quot;, round(r_squared, 2))\r# Create ggplot\rggplot(data, aes(x = Settlement, y = Recreation)) +\rgeom_point(alpha = 0.3) +\rgeom_smooth(method = \u0026quot;lm\u0026quot;, color = 4) +\rgeom_text(aes(label = as.character(label), x = 5, y = 11), hjust = 0, vjust = 0, color = 4) +\rtheme_minimal() +\rlabs(title = \u0026quot;Settlement vs Recreation\u0026quot;, x = \u0026quot;Recreation Area (%)\u0026quot;, y = \u0026quot;Settlement Area (%)\u0026quot;)\r## `geom_smooth()` using formula = 'y ~ x'\rMinimum assumptions Now we check for the homogeneity of the variance of residuals (homoscedasticity) and the normality of the residuals. For this, we plot the fitted values against the residuals and create a QQ-Plot.\nlibrary(gridExtra)\r# Plot 1: Residuals vs Fitted\rp1 \u0026lt;- ggplot(data.frame(Fitted = fitted(model), Residuals = residuals(model)), aes(x = Fitted, y = Residuals)) +\rgeom_point() +\rgeom_smooth(se = FALSE, color = 4) +\rlabs(title = \u0026quot;Residuals vs Fitted\u0026quot;, x = \u0026quot;Fitted Values\u0026quot;, y = \u0026quot;Residuals\u0026quot;) +\rtheme_minimal()\r# Plot 2: Normal Q-Q Plot\rp2 \u0026lt;- ggplot(data.frame(residuals = residuals(model)), aes(sample = residuals)) +\rstat_qq() +\rstat_qq_line(color = 4) +\rlabs(title = \u0026quot;Normal Q-Q Plot\u0026quot;, x = \u0026quot;Theoretical Quantiles\u0026quot;, y = \u0026quot;Sample Quantiles\u0026quot;) +\rtheme_minimal()\r# Arrange the plots side by side\rgrid.arrange(p1, p2, ncol = 2)\rThe plots show that the residuals are neither homoscedastic nor normally distributed, so we should have used a generalized model.\nEvaluation of the Shapiro-Wilk test Now we evaluate how often a normal distribution test on the residuals would reject it’s null-hypothesis if a regression model is not computed on the entire data set but 100 regression models are computed on 100 sub-samples of the data set. The following code creates 100 random subsets with 50 Objects of the full data frame. For each subset we calculate a linear model. We use the Shapiro-Wilk test to test the residuals of the models for normal distribution. The p-values are being saved in a data frame and displayed in a histogram. The null hypothesis of the Shapiro-Wilk test is that the data is normally distributed. The p-value states the probability of the null hypothesis.\nrandom_subsets \u0026lt;- list()\rresults \u0026lt;- data.frame(Iteration = integer(0), P_Value = numeric(0))\r# Set the seed once for reproducibility\rset.seed(123) for (i in 1:100) {\rrandom_indices \u0026lt;- sample(nrow(data), 50)\rrandom_subsets[[i]] \u0026lt;- data[random_indices, ]\rlinear_model \u0026lt;- lm(Settlement ~ Recreation, random_subsets[[i]])\rp_value \u0026lt;- shapiro.test(resid(linear_model))$p.value\rresults \u0026lt;- rbind(results, data.frame(Iteration = i, P_Value = p_value))\r}\rggplot(results, aes(x = P_Value)) +\rgeom_histogram(bins = 40) +\rgeom_vline(xintercept = 0.0375, color = 4, linetype = \u0026quot;dashed\u0026quot;) +\rlabs(title = \u0026quot;Histogram of P-Values\u0026quot;, x = \u0026quot;P-Value\u0026quot;, y = \u0026quot;Frequency\u0026quot;)+\rgeom_text(aes(label = \u0026quot;p-value of 0.05\u0026quot;, x = 0.075, y = 20), hjust = 0, vjust = 0, color = 4)\r![]unnamed-chunk-4-1.png)\nIn 77 of the 100 cases the p-value of the Shapiro-Wilk test is beneath or equal 0.05 which matches with the graphical analysis we did before. However, in 23 cases, the null hypothesis cannot be rejected. The variability in the test results across different subsets highlights the influence of sample size and selection on the performance of normality tests like Shapiro-Wilk and shows how randomness in sub sampling can lead to subsets that are not representative of the entire dataset.\n","date":"2023-11-24T00:00:00Z","permalink":"https://demo.stack.jimmycai.com/p/assignment-05-data-analysis/","title":"Assignment 05 - Data analysis"},{"content":" Unmarked Assignment: Cleaning Crops In this assignment we read and clean our data to prepare it for data analysis. First we take a look at the data: 1. Problems to solve Skip first 6 and last 5 rows of the file Set right encoding to read Umlaute properly Read file with the first 3 column names missing Identify the missing values and replace them with NA Divide column 3 into 3 different columns Fill up the 3 different columns with missing information like “Land” and “Landkreis” Set a new order of the columns and sort the data frame by id and year 2. Problem solving We try to read the data for the first time. Also we save nrow(data) so that we know how many rows there are in the data frame to skip the last 5.\ndata \u0026lt;- read.csv2(file = \u0026quot;../../data/115-46-4_feldfruechte.txt\u0026quot;, header = TRUE, skip = 6, encoding = 'latin1', col.names = c(\u0026quot;Year\u0026quot;, \u0026quot;ID\u0026quot;, \u0026quot;Location\u0026quot;, \u0026quot;Winter_Wheat\u0026quot;, \u0026quot;Rye_and_Winter_Mixed_Grain\u0026quot;, \u0026quot;Winter_Barley\u0026quot;, \u0026quot;Spring_Barley\u0026quot;, \u0026quot;Oats\u0026quot;, \u0026quot;Triticale\u0026quot;, \u0026quot;Potatoes\u0026quot;, \u0026quot;Sugar_Beets\u0026quot;, \u0026quot;Winter_Rapeseed\u0026quot;, \u0026quot;Silage_Maize\u0026quot;))\rnrows \u0026lt;- nrow(data)\rNow we can open the data view tool of r studio and sort the column by their values to find the na.strings. There you will find “.”, “-” and “/”. Now we read the data again. With str(data) we check if r read the data correctly.\ndata \u0026lt;- read.csv2(file = \u0026quot;../../data/115-46-4_feldfruechte.txt\u0026quot;, header = TRUE, skip = 6, encoding = 'latin1', na.string = c(\u0026quot;.\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;/\u0026quot;), nrows = nrows - 5, col.names = c(\u0026quot;Year\u0026quot;, \u0026quot;ID\u0026quot;, \u0026quot;Location\u0026quot;, \u0026quot;Winter_Wheat\u0026quot;, \u0026quot;Rye_and_Winter_Mixed_Grain\u0026quot;, \u0026quot;Winter_Barley\u0026quot;, \u0026quot;Spring_Barley\u0026quot;, \u0026quot;Oats\u0026quot;, \u0026quot;Triticale\u0026quot;, \u0026quot;Potatoes\u0026quot;, \u0026quot;Sugar_Beets\u0026quot;, \u0026quot;Winter_Rapeseed\u0026quot;, \u0026quot;Silage_Maize\u0026quot;))\rstr(data)\r## 'data.frame': 8925 obs. of 13 variables:\r## $ Year : int 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ...\r## $ ID : chr \u0026quot;DG\u0026quot; \u0026quot;01\u0026quot; \u0026quot;01001\u0026quot; \u0026quot;01002\u0026quot; ...\r## $ Location : chr \u0026quot;Deutschland\u0026quot; \u0026quot; Schleswig-Holstein\u0026quot; \u0026quot; Flensburg, Kreisfreie Stadt\u0026quot; \u0026quot; Kiel, Landeshauptstadt, Kreisfreie Stadt\u0026quot; ...\r## $ Winter_Wheat : num 81.5 100.3 94 99.2 99.5 ...\r## $ Rye_and_Winter_Mixed_Grain: num 56.6 79 0 73.9 84.7 79.7 87.5 76.9 79.6 77.4 ...\r## $ Winter_Barley : num 76.9 101.7 94.5 100.7 116.8 ...\r## $ Spring_Barley : num 54.2 59.1 0 0 0 0 0 0 0 0 ...\r## $ Oats : num 45.1 60.5 0 0 0 0 0 0 0 0 ...\r## $ Triticale : num 64.7 80.4 0 0 0 0 0 0 0 0 ...\r## $ Potatoes : num 438 420 0 0 0 ...\r## $ Sugar_Beets : num 722 716 0 701 661 ...\r## $ Winter_Rapeseed : num 39.1 42.6 41.1 45.1 44.8 36 44.1 40 42.7 45.2 ...\r## $ Silage_Maize : num 414 406 390 450 465 ...\rread.csv2() reads files with following default settings (e.g seperator = “,”, dec = “,”) skip = 6 skips the first 6 rows na.strings = c(\u0026quot;.\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;/\u0026quot;) replaces missing values with NA´s setting the column names while reading the data prevents error while reading the data with 3 missing column names encoding = 'latin1' allows Umlaute nrows = nrows - 5ignores the last 5 rows Now we have to divide the third column into 3. We want one column to contain the name of the place. The second column should contain information about the administrative unit. The third column should contain additional information like “Hansestadt”. For that we create 2 new empty rows. To dived the column we use the clean_administrativ_area() function, we created in the function-script. Lastly we set the column in the right order and sort the rows by the ID and year.\nsource(\u0026quot;functions.R\u0026quot;)\rdata$administrative_unit \u0026lt;- NA\rdata$additional_info \u0026lt;- NA\rdata \u0026lt;- cleaning_administrativ_area(data, data$Location)\rdata \u0026lt;- data[,c(2,1,3,14,15,4,5,6,7,8,9,10,11,12,13)]\rdata \u0026lt;- data[order(data$ID,data$Year), ]\rrownames(data) \u0026lt;- 1:nrow(data)\rClick here to view the code for the function\rcleaning_administrative_area()\r#A function to clean administrative area data in a data frame\rcleaning_administrativ_area \u0026lt;- function(dataframe, column){\r# Split the specified column on commas\rsplit_data \u0026lt;- strsplit(column, \u0026quot;,\u0026quot;)\r#create a matrix out of the split_data\rextracted \u0026lt;- t(sapply(split_data, function(x) x[1:3]))\r# Convert the matrix to a data frame\rdf \u0026lt;- as.data.frame(extracted)\rnames(df) \u0026lt;- c(\u0026quot;one\u0026quot;, \u0026quot;two\u0026quot;, \u0026quot;three\u0026quot;)\r# Identify rows where the third column is not NA for swapping\rswap_idx \u0026lt;- !is.na(df$three)\r# Perform the swap of 'two' and 'three' where the third column is not NA\rtemp \u0026lt;- df$two[swap_idx]\rdf$two[swap_idx] \u0026lt;- df$three[swap_idx]\rdf$three[swap_idx] \u0026lt;- temp\r# Fill missing values in 'two' based on how far the place is idented\rdf$two[is.na(df$two) \u0026amp; regexpr(\u0026quot;\\\\S\u0026quot;, df$one)==1] \u0026lt;- \u0026quot;Land\u0026quot;\rdf$two[is.na(df$two) \u0026amp; regexpr(\u0026quot;\\\\S\u0026quot;, df$one)==3] \u0026lt;- \u0026quot;Bundesland\u0026quot;\rdf$two[is.na(df$two) \u0026amp; regexpr(\u0026quot;\\\\S\u0026quot;, df$one)==7] \u0026lt;- \u0026quot;Landkreis\u0026quot;\r# Trim leading whitespace from 'one', 'two', and 'three'\rdf$one \u0026lt;- sub(\u0026quot;^\\\\s+\u0026quot;, \u0026quot;\u0026quot;, df$one)\rdf$two \u0026lt;- sub(\u0026quot;^\\\\s+\u0026quot;, \u0026quot;\u0026quot;, df$two)\rdf$three \u0026lt;- sub(\u0026quot;^\\\\s+\u0026quot;, \u0026quot;\u0026quot;, df$three)\r# Update the original dataframe with the new columns\rdataframe$Location \u0026lt;- df$one\rdataframe$administrative_unit \u0026lt;- df$two\rdataframe$additional_info \u0026lt;- df$three\r# Return the modified dataframe\rreturn(dataframe)\r}\r3. Resulting data frame head(data)\r## ID Year Location administrative_unit additional_info Winter_Wheat\r## 1 01 1999 Schleswig-Holstein Bundesland \u0026lt;NA\u0026gt; 91.9\r## 2 01 2000 Schleswig-Holstein Bundesland \u0026lt;NA\u0026gt; 96.5\r## 3 01 2001 Schleswig-Holstein Bundesland \u0026lt;NA\u0026gt; 98.4\r## 4 01 2002 Schleswig-Holstein Bundesland \u0026lt;NA\u0026gt; 81.6\r## 5 01 2003 Schleswig-Holstein Bundesland \u0026lt;NA\u0026gt; 86.4\r## 6 01 2004 Schleswig-Holstein Bundesland \u0026lt;NA\u0026gt; 90.7\r## Rye_and_Winter_Mixed_Grain Winter_Barley Spring_Barley Oats Triticale Potatoes\r## 1 67.6 86.8 56.3 59.2 67.2 376.6\r## 2 67.1 81.7 54.9 53.7 71.4 379.6\r## 3 73.2 87.2 49.6 56.1 77.4 370.4\r## 4 64.9 74.4 44.4 50.2 67.2 328.9\r## 5 67.1 79.6 53.0 61.7 73.2 347.7\r## 6 69.7 84.4 51.3 61.4 72.6 402.0\r## Sugar_Beets Winter_Rapeseed Silage_Maize\r## 1 543.7 39.7 378.4\r## 2 555.3 39.5 356.8\r## 3 538.3 41.1 385.1\r## 4 533.7 32.0 372.3\r## 5 546.3 37.9 343.9\r## 6 572.1 44.2 354.5\r","date":"2023-11-16T00:00:00Z","permalink":"https://demo.stack.jimmycai.com/p/assignment-04-data-analysis/","title":"Assignment 04 - Data analysis"},{"content":" Warm up spatial This is a follow-along exercise to get familiar with handling spatial data in R. First we read our geoAI_setup file to get our directories and load our packages\nsource(\u0026quot;geoAI_setup.R\u0026quot;)\rNow we read our raster excerpt with the rast-function of the terra package.\ndop \u0026lt;- terra::rast(paste0(envrmt$path_data_level1,\u0026quot;/marburg_dop_excerpt.tif\u0026quot;))\rWe download building data from open street map and get the polygons.\nbuildings \u0026lt;- osmdata::opq(bbox = \u0026quot;marburg de\u0026quot;) %\u0026gt;%\rosmdata::add_osm_feature(key = \u0026quot;building\u0026quot;) %\u0026gt;%\rosmdata::osmdata_sf()\rbuildings \u0026lt;- buildings$osm_polygons\rWe check the if the projections are the same and transform them to match.\nterra::same.crs(dop,buildings)\r## [1] FALSE\rbuildings \u0026lt;- sf::st_transform(buildings, terra::crs(dop))\rterra::same.crs(dop,buildings)\r## [1] TRUE\rNow we can take a look at the raster.\nterra::plotRGB(dop)\rWe can calculate different indices with the given bands.\n# Extract individual bands from the DOP for further analysis\rred \u0026lt;- dop[[1]]\rgreen \u0026lt;- dop[[2]]\rblue \u0026lt;- dop[[3]]\r# Calculate the Normalized Difference Turbidity Index (NDTI)\rNDTI \u0026lt;- (red -green) / (red + green)\rnames(NDTI) \u0026lt;- \u0026quot;NDTI\u0026quot;\r# Calculate the Visible Atmospherically Resistant Index (VARI)\rVARI \u0026lt;- (green - red) / (green + red - blue)\rnames(VARI) \u0026lt;- \u0026quot;VARI\u0026quot;\r# Calculate the Triangular Greenness Index (TGI)\rTGI \u0026lt;- -0.5 * (190 * (red - green) - 120 * (red - blue))\rnames(TGI) \u0026lt;- \u0026quot;TGI\u0026quot;\r# Combine the indices into a single stack for plotting\rrgbI \u0026lt;- c(NDTI, VARI, TGI)\rterra::plot(rgbI)\rLastly we can combine the original raster with the newly calculated indicies into object and save it.\ndop_indices \u0026lt;- c(dop, rgbI)\rsaveRDS(dop_indices, file.path(envrmt$path_data, \u0026quot;dop_indices.RDS\u0026quot;))\r","date":"2023-11-12T00:00:00Z","permalink":"https://demo.stack.jimmycai.com/p/assignment-01-03-geoai/","title":"Assignment 01-03 - GeoAI"},{"content":" Marked Assignment: Read and Plot 1. Task Read the data provided in the Excel file and “isolate” the tabulated information into a data.frame class. First we take a look at the data: We need to read the data with ; as separator and skip the first 4 and the last line of the .txt. Also we set year 2010 to 2014 of colored woods to NA, because they were counted as beechs since 2010.\ndata \u0026lt;- read.table(file = \u0026quot;../../data/hessen_holzeinschlag_1997-2014.csv\u0026quot;, header = TRUE, skip =4, sep = \u0026quot;;\u0026quot;, nrow = 18)\rcolnames(data) \u0026lt;- c(\u0026quot;Year\u0026quot;, \u0026quot;Oak\u0026quot;, \u0026quot;Beech\u0026quot;, \u0026quot;ColoredWoods\u0026quot;, \u0026quot;Spruce\u0026quot;, \u0026quot;Pine\u0026quot;, \u0026quot;Total\u0026quot;)\rdata[which(data$Year\u0026gt; 2009),4] \u0026lt;- NA\rprint(data)\r## Year Oak Beech ColoredWoods Spruce Pine Total\r## 1 1997 155 1036 21 1684 779 3675\r## 2 1998 265 1631 36 1761 951 4644\r## 3 1999 278 1796 32 1732 914 4752\r## 4 2000 204 1300 0 1024 616 3144\r## 5 2001 322 1515 0 1592 706 4135\r## 6 2002 265 1410 0 2036 663 4374\r## 7 2003 404 1698 0 2482 820 5404\r## 8 2004 400 1572 0 2775 757 5504\r## 9 2005 370 1489 0 2601 887 5347\r## 10 2006 388 1881 0 2580 844 5693\r## 11 2007 271 1816 0 6524 782 9393\r## 12 2008 292 1721 0 3698 661 6372\r## 13 2009 135 1149 0 1926 534 3744\r## 14 2010 223 1733 NA 3201 807 5964\r## 15 2011 297 1908 NA 2018 829 5052\r## 16 2012 281 1821 NA 1685 777 4564\r## 17 2013 284 1821 NA 1721 813 4639\r## 18 2014 285 1911 NA 1704 805 4705\r2. Task Create a simple visualization which gives a quick, temporally non explicit and descriptive statistical overview of the harvest by tree type and as a total over all trees (i.e. a similar kind of information as provided by the summary function). I want to create a box plot with the ggplot2 package, grouped by the different tree types. To do that we first need to transform the data frame from the wide to a long format. For that we can use the tidyr package.\nlibrary(tidyr)\rdata_long \u0026lt;- pivot_longer(data, cols = -Year, names_to = \u0026quot;TreeType\u0026quot;, values_to = \u0026quot;Volume\u0026quot;)\rhead(data_long, n = 12)\r## # A tibble: 12 × 3\r## Year TreeType Volume\r## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt;\r## 1 1997 Oak 155\r## 2 1997 Beech 1036\r## 3 1997 ColoredWoods 21\r## 4 1997 Spruce 1684\r## 5 1997 Pine 779\r## 6 1997 Total 3675\r## 7 1998 Oak 265\r## 8 1998 Beech 1631\r## 9 1998 ColoredWoods 36\r## 10 1998 Spruce 1761\r## 11 1998 Pine 951\r## 12 1998 Total 4644\rNow we can create the box plot and group it by the tree type.\nlibrary(ggplot2)\rggplot(data_long, aes(x = TreeType, y = Volume, group = TreeType)) +\rgeom_boxplot(outlier.shape = NA) +\rgeom_jitter(width = 0.2) + theme_minimal()+\rlabs(x = \u0026quot;Tree Type\u0026quot;, y = expression(Volume~\u0026quot;[1000\u0026quot;~m^3~\u0026quot;]\u0026quot;), title = \u0026quot;Boxplot of Volume by Tree Type in 1000 cubic meter\u0026quot;)\r3. Task Create another visualization which - in the same figure panel - shows how each beech harvest over the time span is related to each of the oak, pine, spruce and colored wood harvests in a 2 by 2 grid (i.e. arrange the figures in a 2 columns and 2 rows layout). This time we will use base R to create the plots. First we create a Layout to arrange to plots in a 2x2 grid, but also add a third row for the legend (so technicly a 2x3 grid). For that we use the layout-function. Inside that function we create a matrix to create different cells for the layout. Because the whole last row should contain the legend we count from 1 to 5 and count 5 two times. We define the number of rows and columns of the layout and adjust the heights of the different rows. Then we can create the plots inside of the layout. At the end we add the legend to the last row.\nlayout(matrix(c(1, 2, 3, 4, 5, 5), 3, 2, byrow = TRUE), heights = c(2, 2, 0.25))\rline_types \u0026lt;- c(\u0026quot;solid\u0026quot;, \u0026quot;dotted\u0026quot;, \u0026quot;dashed\u0026quot;, \u0026quot;dotdash\u0026quot;, \u0026quot;longdash\u0026quot;)\rplot(data$Year, data$Beech, type = \u0026quot;l\u0026quot;, lty = line_types[1], ylim = c(0, 2000),\rxlab = \u0026quot;Year\u0026quot;, ylab = expression(Volume~\u0026quot;[1000\u0026quot;~m^3~\u0026quot;]\u0026quot;), main = \u0026quot;Beech and Oak Volume Over Years\u0026quot;)\rlines(data$Year, data$Oak, lty = line_types[2])\rplot(data$Year, data$Beech, type = \u0026quot;l\u0026quot;, lty = line_types[1], ylim = c(0, 2000), xlab = \u0026quot;Year\u0026quot;, ylab = expression(Volume~\u0026quot;[1000\u0026quot;~m^3~\u0026quot;]\u0026quot;), main = \u0026quot;Beech and Colored Woods Volume Over Years\u0026quot;)\rlines(data$Year, data$ColoredWoods,\rlty = line_types[3])\rplot(data$Year, data$Beech, type = \u0026quot;l\u0026quot;, lty = line_types[1], ylim = c(0, 7000),\rxlab = \u0026quot;Year\u0026quot;, ylab = expression(Volume~\u0026quot;[1000\u0026quot;~m^3~\u0026quot;]\u0026quot;), main = \u0026quot;Beech and Spruce Volume Over Years\u0026quot;)\rlines(data$Year, data$Spruce, lty = line_types[4])\rplot(data$Year, data$Beech, type = \u0026quot;l\u0026quot;, lty = line_types[1], ylim = c(0, 2000),\rxlab = \u0026quot;Year\u0026quot;, ylab = expression(Volume~\u0026quot;[1000\u0026quot;~m^3~\u0026quot;]\u0026quot;), main = \u0026quot;Beech and Pine Volume Over Years\u0026quot;)\rlines(data$Year, data$Pine, lty = line_types[5])\rpar(mar = c(0, 0, 0, 0))\rplot.new()\rlegend(\u0026quot;bottom\u0026quot;, inset = c(0, -0.2), legend = c(\u0026quot;Beech\u0026quot;, \u0026quot;Oak\u0026quot;, \u0026quot;Colored Woods\u0026quot;, \u0026quot;Spruce\u0026quot;, \u0026quot;Pine\u0026quot;), bty = \u0026quot;n\u0026quot;,title = NA, lty = c(line_types[1], line_types[2], line_types[3], line_types[4], line_types[5]), horiz = TRUE)\r4. Task Include your opinion on what could be the key message of these figures in two sentence max. The data shows a notable decrease in spruce harvest volumes in 2007, a result of its vulnerability to factors such as the Kyrill storm, bark beetle infestations, and elevated temperatures. In contrast, other nativ tree species did not exhibit a similar increase in harvest volume that year, underscoring the importance of tailoring forest management to the unique responses of different species to environmental stressors and climate change.\n","date":"2023-11-12T00:00:00Z","permalink":"https://demo.stack.jimmycai.com/p/assignment-03-data-analysis/","title":"Assignment 03 - Data analysis"},{"content":" Unmarked Assignment: Loop and Conquer 1. Implement an if-then-else statement which prints “larger” if the number provided as variable n is larger than three and “equal or smaller” otherwise. check_value \u0026lt;- function(n){\rif(n \u0026gt;3){\rprint(\u0026quot;large\u0026quot;)\r}else{\rprint(\u0026quot;equal or smaller\u0026quot;)\r}\r}\rcheck_value(2)\r[1] \u0026quot;equal or smaller\u0026quot;\r2. Extent a copy of the above statement (i.e. copy the entire if-then-else statement and include it a second time in your script in order to preserve both versions) which returns “equal” and “smaller” explicitly in addition to “larger”. check_value \u0026lt;- function(n){\rif(n \u0026gt;3){\rprint(\u0026quot;large\u0026quot;)\r}else if(n == 3){\rprint(\u0026quot;equal\u0026quot;)\r}else if(n \u0026lt;3){\rprint(\u0026quot;smaller\u0026quot;)\r}\r}\rcheck_value(2)\r[1] \u0026quot;smaller\u0026quot;\r3. Implement a if-then-else statement which prints “even” if the number provided as variable n is even and which prints “odd” otherwise. even_or_odd \u0026lt;- function(n){\rif(n %% 2 == 0){\rprint(\u0026quot;even\u0026quot;)\r}else{\rprint(\u0026quot;odd\u0026quot;)\r}\r}\reven_or_odd(5)\r[1] \u0026quot;odd\u0026quot;\r4. Copy the extended larger/equal/smaller if-then-else statement and include it into a for loop which shows that all three options are actually implemented in a correct manner by iterating over n from a number which is smaller 3, exactly 3 and larger than 3. check_value \u0026lt;- function(n){\rif(n \u0026gt;3){\rprint(\u0026quot;large\u0026quot;)\r}else if(n == 3){\rprint(\u0026quot;equal\u0026quot;)\r}else if(n \u0026lt;3){\rprint(\u0026quot;smaller\u0026quot;)\r}\r}\rfor(n in c(2,3,4)){\rcheck_value(n)\r}\r[1] \u0026quot;smaller\u0026quot;\r[1] \u0026quot;equal\u0026quot;\r[1] \u0026quot;large\u0026quot;\r5. Extent a copy of the above loop and modify the loop and if-then-else statement in such a way, that the information on “larger” etc. is not printed on the screen but saved within a vector (i.e. a variable which will hold all three statements in the end). Print the content of this vector after the loop. v1 \u0026lt;- c()\rcheck_value \u0026lt;- function(n){\rif(n \u0026gt;3){\rprint(\u0026quot;large\u0026quot;)\r}else if(n == 3){\rprint(\u0026quot;equal\u0026quot;)\r}else if(n \u0026lt;3){\rprint(\u0026quot;smaller\u0026quot;)\r}\r}\rfor(n in c(2,3,4)){\rv1 \u0026lt;- c(v1,check_value(n))\r}\r[1] \u0026quot;smaller\u0026quot;\r[1] \u0026quot;equal\u0026quot;\r[1] \u0026quot;large\u0026quot;\rprint(v1)\r[1] \u0026quot;smaller\u0026quot; \u0026quot;equal\u0026quot; \u0026quot;large\u0026quot; 6. Extent a copy of the above modified loop in such a way, that the results are not saved in a vector but a list. Print the content of this list after the loop. l1 \u0026lt;- list()\rcheck_value \u0026lt;- function(n){\rif(n \u0026gt;3){\rprint(\u0026quot;large\u0026quot;)\r}else if(n == 3){\rprint(\u0026quot;equal\u0026quot;)\r}else if(n \u0026lt;3){\rprint(\u0026quot;smaller\u0026quot;)\r}\r}\rfor(n in c(2,3,4)){\rl1[length(l1) + 1] \u0026lt;- check_value(n)\r}\r[1] \u0026quot;smaller\u0026quot;\r[1] \u0026quot;equal\u0026quot;\r[1] \u0026quot;large\u0026quot;\rprint(l1)\r[[1]]\r[1] \u0026quot;smaller\u0026quot;\r[[2]]\r[1] \u0026quot;equal\u0026quot;\r[[3]]\r[1] \u0026quot;large\u0026quot;\r7. Change the above modified loop in such a way, that the iteration is controlled by a lapply not by a for-loop. Save the returning information from the lapply function in a variable and print the content of this variable after the loop. l1 \u0026lt;- list()\rcheck_value \u0026lt;- function(n){\rif(n \u0026gt;3){# testesttest\rprint(\u0026quot;large\u0026quot;)\r}else if(n == 3){\rprint(\u0026quot;equal\u0026quot;)\r}else if(n \u0026lt;3){\rprint(\u0026quot;smaller\u0026quot;)\r}\r}\rvalues \u0026lt;- c(2,3,4)\rresult \u0026lt;- lapply(values, check_value)\r[1] \u0026quot;smaller\u0026quot;\r[1] \u0026quot;equal\u0026quot;\r[1] \u0026quot;large\u0026quot;\rprint(result)\r[[1]]\r[1] \u0026quot;smaller\u0026quot;\r[[2]]\r[1] \u0026quot;equal\u0026quot;\r[[3]]\r[1] \u0026quot;large\u0026quot;\r8. Finally change the above variable (i.e. do not modify the loop anymore but just include one more line) in such a way that the content is not printed as a nested list but a vector (i.e. flatten the list). check_value \u0026lt;- function(n){\rif(n \u0026gt; 3){\rreturn(\u0026quot;larger\u0026quot;)\r}else if(n == 3){\rreturn(\u0026quot;equal\u0026quot;)\r}else if(n \u0026lt; 3){\rreturn(\u0026quot;smaller\u0026quot;)\r}\r}\rvalues \u0026lt;- c(2,3,4)\rresult \u0026lt;- lapply(values, check_value)\rresult \u0026lt;- unlist(result)\rprint(result)\r[1] \u0026quot;smaller\u0026quot; \u0026quot;equal\u0026quot; \u0026quot;larger\u0026quot; ","date":"2023-11-07T00:00:00Z","permalink":"https://demo.stack.jimmycai.com/p/assignment-02-data-analysis/","title":"Assignment 02 - Data analysis"},{"content":"Marked Assignment: Hello R, Hello GitHub 1. Assign the value of five to a variable called a and the value of two to a variable called b. a \u0026lt;- 5\rb \u0026lt;- 2\r2. Compute the sum, difference, product and ratio of a and b (a always in the first place) and store the results to four different variables called r1, r2, r3, and r4. r1 \u0026lt;- a+b\rr2 \u0026lt;- a-b\rr3 \u0026lt;- a*b\rr4 \u0026lt;- a/b\r3. Create a vector v1 which contains the values stored within the four variables from step 2. v1 \u0026lt;- c(r1,r2,r3,r4)\r4. Add a fifth entry to vector v1 which represents a by the power of b (i.e. a**b). v1 \u0026lt;- c(v1,a**b)\r5. Show the content of vector v1 (e.g. use the print function or just type the variable name in a separate row). print(v1)\r## [1] 7.0 3.0 10.0 2.5 25.0\r6. Create a second vector v2 which contains information on the type of mathematical operation used to derive the five results. Hence this vector should have five entries of values sum, difference,… v2 \u0026lt;- c(\u0026quot;sum\u0026quot;, \u0026quot;difference\u0026quot;, \u0026quot;product\u0026quot;, \u0026quot;ratio\u0026quot;, \u0026quot;exponentiation\u0026quot;)\r7. Show the content of vector v2. print(v2)\r## [1] \u0026quot;sum\u0026quot; \u0026quot;difference\u0026quot; \u0026quot;product\u0026quot; \u0026quot;ratio\u0026quot; \u0026quot;exponentiation\u0026quot;\r8. Combine the two vectors v1 and v2 into a data frame called df. Each vector should become one column of the data frame so you will end up with a data frame having 5 rows and 2 columns. df \u0026lt;- data.frame(v1,v2)\r9. Make sure that the column with the data of v1 is named Results and v2 is named Operation. colnames(df) \u0026lt;- c(\u0026quot;Results\u0026quot;, \u0026quot;Operation\u0026quot;)\r10. Show the entire content of df. print(df)\r## Results Operation\r## 1 7.0 sum\r## 2 3.0 difference\r## 3 10.0 product\r## 4 2.5 ratio\r## 5 25.0 exponentiation\r11. Show just the entry of the cell in the second row and first column. print(df[2,1])\r## [1] 3\r","date":"2023-10-31T00:00:00Z","permalink":"https://demo.stack.jimmycai.com/p/assignment-01-data-analysis/","title":"Assignment 01 - Data analysis"}]